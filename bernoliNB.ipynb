{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bernoliNB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farooqzaman1/DataSciencePrj/blob/master/bernoliNB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2jvaYtLkoSuU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Quora Insincere Questions Classification\n",
        "#Detect toxic content to improve online conversations\n",
        "An existential problem for any major website today is how to handle toxic and divisive content. Quora wants to tackle this problem head-on to keep their platform a place where users can feel safe sharing their knowledge with the world.\n",
        "\n",
        "Quora is a platform that empowers people to learn from each other. On Quora, people can ask questions and connect with others who contribute unique insights and quality answers. A key challenge is to weed out insincere questions -- those founded upon false premises, or that intend to make a statement rather than look for helpful answers.\n",
        "\n",
        "In this competition, Kagglers will develop models that identify and flag insincere questions. To date, Quora has employed both machine learning and manual review to address this problem. With your help, they can develop more scalable methods to detect toxic and misleading content.\n",
        "\n",
        "Here's your chance to combat online trolls at scale. Help Quora uphold their policy of “Be Nice, Be Respectful” and continue to be a place for sharing and growing the world’s knowledge.\n"
      ]
    },
    {
      "metadata": {
        "id": "0bJf2RWXoEgn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing required libararies**\n"
      ]
    },
    {
      "metadata": {
        "id": "yur6vbvihw9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m0P9VC_Uu6IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f6c7a020-16f7-4bdb-bee2-764a760f8e87"
      },
      "cell_type": "code",
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyDrive\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
            "\u001b[K    100% |████████████████████████████████| 993kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.11.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.4)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Building wheels for collected packages: PyDrive\n",
            "  Running setup.py bdist_wheel for PyDrive ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
            "Successfully built PyDrive\n",
            "Installing collected packages: PyDrive\n",
            "Successfully installed PyDrive-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xSVc8fP8qRNs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using google drive for project data resources**"
      ]
    },
    {
      "metadata": {
        "id": "6RhnVAU8kYqj",
        "colab_type": "code",
        "outputId": "73dda3b7-13b4-4020-ef53-40a742f041eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "# # files.upload()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QtkqfG8rq9pj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**loading dataset**"
      ]
    },
    {
      "metadata": {
        "id": "kSCpvl7tjTg2",
        "colab_type": "code",
        "outputId": "7ffdfde8-b1be-41da-b633-fa65d9adf752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv(\"drive/My Drive/DataScienceProject/train.csv\")\n",
        "print(\"total Instances: \",data.shape[0])\n",
        "\n",
        "data=data.sort_values(by=['target'])\n",
        "\n",
        "print(\"class 1: \",data['target'].sum(), \"class 0: \", len(data['target'])-data['target'].sum())\n",
        "SampleIndex=data['target'].sum() * 2 + 1000\n",
        "\n",
        "dataSample= data[-SampleIndex:]\n",
        "print(\"Selected Subset: \",dataSample.shape[0])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total Instances:  1306122\n",
            "class 1:  80810 class 0:  1225312\n",
            "Selected Subset:  162620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RsriJCCZrvMi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Droping Nan values**"
      ]
    },
    {
      "metadata": {
        "id": "lwXpNb2orgSa",
        "colab_type": "code",
        "outputId": "3eeaced6-42f3-43ba-e807-60d2a03f08a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "data = data[pd.notnull(data['target'])]\n",
        "\n",
        "print(\"is there any null?\")\n",
        "print(data.isna().sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is there any null?\n",
            "qid              0\n",
            "question_text    0\n",
            "target           0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vjqpg7yer75u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Splitting data into train and test part**\n"
      ]
    },
    {
      "metadata": {
        "id": "nYMYBPF4rl0L",
        "colab_type": "code",
        "outputId": "fb2f05f4-44fe-40d6-8d06-65c77abb1a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(dataSample, test_size=0.3)\n",
        "\n",
        "X_train = train['question_text']\n",
        "y_train = train['target']\n",
        "\n",
        "    \n",
        "X_test = test['question_text']\n",
        "y_test = test['target']\n",
        "print(\"Training on :\", len(train['target']))\n",
        "print(\"test on: \", len(test['target']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on : 113834\n",
            "test on:  48786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ssz7z2Ftn-7n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Helper Function for reading Files**"
      ]
    },
    {
      "metadata": {
        "id": "tgOcLO1vj8qD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read Files\n",
        "def load_doc(filename):\n",
        "\tfile = open(filename, 'r', encoding=\"utf-8\")\n",
        "\ttext = file.read()\n",
        "\tfile.close()\n",
        "\treturn text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKZg2mN1twVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create list of valid tokens from text**"
      ]
    },
    {
      "metadata": {
        "id": "eRWTWDY1tvGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create tokens of text, remove punctuation marks and filter out invalid tokens\n",
        "def clean_question(quest, vocab):\n",
        "\t# create tokens using white space\n",
        "\ttokens = quest.split()\n",
        "\t# remove punctuation\n",
        "\ttable = str.maketrans('', '', punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove tokens not in vocab\n",
        "\ttokens = [w for w in tokens if w in vocab]\n",
        "\ttokens = ' '.join(tokens)\n",
        "\treturn tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjqgpIDUuAdD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**process list of documents**"
      ]
    },
    {
      "metadata": {
        "id": "q5trikMIj2uu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function to process and clean all questions\n",
        "def process_docs(docs, vocab,):\n",
        "    questionss = list()\n",
        "    for d in docs:\n",
        "        tokens = clean_question(d, vocab)\n",
        "        questionss.append(tokens)\n",
        "    return questionss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clJ97ar6udoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading vocablary previously created  on complete data**"
      ]
    },
    {
      "metadata": {
        "id": "nW0Le5b_uefd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the vocabulary\n",
        "vocab_filename = 'drive/My Drive/DataScienceProject/vocab.txt'\n",
        "vocab = load_doc(vocab_filename)\n",
        "vocab = vocab.split()\n",
        "vocab = set(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49Xt6trJutpa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Process all training Questions**"
      ]
    },
    {
      "metadata": {
        "id": "y_rkAb5TjyZA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# process all training Questions\n",
        "train_docs = process_docs(X_train, vocab)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMHRTx0EvpZ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create tokenizer and convert text to sequences of maximum question length**"
      ]
    },
    {
      "metadata": {
        "id": "W6KNAbD2vqMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "# fit the tokenizer on the document\n",
        "tokenizer.fit_on_texts(train_docs)\n",
        "\n",
        "# sequence encode\n",
        "encoded_docs = tokenizer.texts_to_sequences(train_docs)\n",
        "# pad sequences\n",
        "max_length = max([len(s.split()) for s in train_docs])\n",
        "Xtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_tl-EAlxO7I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Applying Bernoulli Naive Bayes from sklearn**"
      ]
    },
    {
      "metadata": {
        "id": "gvhI_gLhjk3U",
        "colab_type": "code",
        "outputId": "1b9c275a-731a-4470-b231-179dbb522cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = BernoulliNB()\n",
        "model.fit(Xtrain, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "3nsJ6kc8wHYe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load test data and create text sequences of max document length**"
      ]
    },
    {
      "metadata": {
        "id": "eAPI2X55wH-x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# process all test questions and convert it to numerical form\n",
        "test_docs = process_docs(X_test, vocab)\n",
        "# fit the tokenizer on the documents\n",
        "tokenizer.fit_on_texts(test_docs)\n",
        "# sequence encode\n",
        "encoded_docs = tokenizer.texts_to_sequences(test_docs)\n",
        "# pad sequences\n",
        "max_length = max([len(s.split()) for s in train_docs])\n",
        "Xtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-x5Ic6iPwl8d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Test predictions**"
      ]
    },
    {
      "metadata": {
        "id": "UpQP_K_-jjvQ",
        "colab_type": "code",
        "outputId": "914001cb-a043-4d1c-de91-028ddd85ff27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred= (model.predict(Xtest))\n",
        "sc1 = accuracy_score(y_test, y_pred)\n",
        "print(\"Acc=\",sc1)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc= 0.6400196777764112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O_YPdkh7wxtF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "metadata": {
        "id": "a7YdxyhXwyYA",
        "colab_type": "code",
        "outputId": "484558a7-3018-4d35-94f6-a59a9e3eccf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "\n",
        "print( \"tp=\",tp, \"tn =\",tn, \" fp=\",fp, \" fn=\",fn)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tp= 12667 tn = 18557  fp= 6100  fn= 11462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GjA5l2now-HA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Percision, Recall and F Measure**"
      ]
    },
    {
      "metadata": {
        "id": "wMvW4Eo2w-qu",
        "colab_type": "code",
        "outputId": "7426720c-a8a6-4769-9be5-658c535c1a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "P = tp/(tp+fn)\n",
        "R= tp/(tp+fp)\n",
        "accuracy = (tp+tn)/(tn + fp + fn + tp)\n",
        "F1=2*P*R/(P+R)\n",
        "print(\"Accuracy= \",np.round(accuracy,2),\"precission=\",np.round(P,2),\"recall=\",np.round(R,2),\" F1=\",np.round(F1,2))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy=  0.64 precission= 0.52 recall= 0.67  F1= 0.59\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}